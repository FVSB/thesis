\chapter{Preliminares}\label{chapter:state-of-the-art}



La optimización binivel es un problema de optimización donde un subconjunto de variables debe ser la solución óptima de otro problema de optimización, parametrizado por las variables restantes. Este problema tiene dos niveles jerárquicos de decisión: el nivel superior (líder) y el nivel inferior (seguidor).
Este tiene dos características principales: primero, el problema del nivel inferior actúa como una restricción para el nivel superior; segundo, la solución del nivel inferior depende de las variables del nivel superior, creando una interdependencia entre ambos niveles. Por ello, el líder debe anticipar la respuesta óptima del seguidor al tomar decisiones.
%Explicación breve de binivel
En términos abstractos, la optimización binivel busca minimizar una función objetivo de nivel superior, $F(x, y)$, donde $x$ son las variables de decisión del líder y $y$ son las variables del seguidor. 

% Explicación del capitulo
En este capítulo se abordará los conocimientos necesarios para el desarrollo de esta tesis. Consta de secciones sobre los conceptos fundamentales de la Optimización Binivel del Caso Optimista, así como su reformulación KKT,
además de nociones clave sobre los Problemas Matemáticos con Restricciones de Equilibrio (MPEC), 
y por último la modelación de los problemas binivel en el lenguaje de programación Julia y métodos seleccionados implementados en este lenguaje para su resolución. 

\section{Optimización Binivel }
%Intro de la sección
El problema de optimización binivel en general se define de la siguiente manera
\begin{equation} \label{eq:Def1Binivel}
    \begin{array}{l}
       \min_{x} \quad F(x, y)\\
        s.a \left\{ \begin{array}{l}
            x \in T \\
             y \in S(x) = \arg  \min_{y} \{ f(x, y) \quad s.a \quad y \in  \cal{H}\\
            x,y \in M^0 
        \end{array}\right.
        \end{array} \end{equation}
En la mayoria de las aplicaciones, los problemas de optimizacion del nivel inferior y superior son modelos de programacion matematica, por lo  que tienen la estructura  *** con S(x)
\begin{equation}
\begin{aligned}
& \min_{x} \; F(x, y) \\
& \text{sujeto a } \\
& G(x) \leq 0, \\
& y \in \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
\end{aligned}
\label{eq:ProblemaGeneral}
\end{equation}
Para reducir las notaciones asumimos que en ambos problemas solo hay restricciones de desigualdad. O sea, se considerara el modelo 
\begin{equation}
\begin{aligned}
& \min_{x} \; F(x, y) \\
& \text{sujeto a } \\
& G(x) \leq 0, \\
& y \in \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
\end{aligned}
\label{eq:ProblemaGeneral}
\end{equation} 
%TODO:
% ***CON S(x)
%Para el concepto de solucion es necesario tener en cuenta la decision de ... parrafo de intro cambiado
%En este sentido, se consideran dos enfoques principales: el optimista y el pesimista.  El problema optimista consiste en  y se 
%% Formulación general de optimización binivel


% DIFERENCIA OPTIMISTA PESIMISTA
% Decir que en el libro de Dempe se hablan de estos dos enfoques
%Enfoque optimista
En el enfoque optimista, se asume que el seguidor, que actúa en el nivel inferior, elegirá la solución más favorable para el líder, quien toma decisiones en el nivel superior. Este es considerado más tratable y, en ciertas situaciones favorables, puede simplificarse a un problema convexo. Además, en el contexto de múltiples objetivos, el enfoque optimista permite alcanzar el mejor frente de Pareto posible, ver \cite{DempeyZemkoho2020}.

%\begin{center}   
%    Bajo el enfoque optimista :
%    \end{center}
    % Enfoque optimista (selección favorable)
    \begin{equation}
    \begin{aligned}
    & \min_{x} \; \inf_{y \in S(x)} F(x, y) \\
    & \text{con } S(x) = \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
    \end{aligned}
    \label{eq:EnfoqueOptimistaGeneral}
    %\caption*{Problema de optimización bajo el enfoque optimista}
    \end{equation}
    \captionof{figure}{Problema de optimización bajo el enfoque optimista.}

% Enfoque pesimista
Por otro lado, el enfoque pesimista asume que el seguidor seleccionará la opción menos favorable para el líder entre las soluciones óptimas disponibles, el cual es más complejo de resolver y puede incluso no tener solución. A menudo, se requieren reformulaciones para abordar estos problemas, lo que lo convierte en un reto teórico y computacional significativo en situaciones de múltiples objetivos, conduce al peor frente de Pareto posible, ver \cite{Sinha2017ARO}.
%\begin{center}
%    Bajo el enfoque pesimista:
%\end{center}
% Enfoque pesimista (peor caso)
\begin{equation}
\begin{aligned}
& \min_{x} \; \sup_{y \in S(x)} F(x, y) \\
& \text{con } S(x) = \argmin_{y} \left\{ f(x, y) \mid v(x, y) \leq 0 \right\}
\end{aligned}
\label{eq:EnfoquePesimistaGeneral}
\end{equation}
\captionof{figure}{Problema de optimización bajo el enfoque pesimista.}
%Decir que el optimista es mejor
Es relevante destacar que la mayoría de la literatura se centra en el enfoque optimista debido a su mayor facilidad de tratamiento. Sin embargo, el otro también tiene su utilidad, especialmente en la modelación de situaciones donde se considera la aversión al riesgo, ver \cite{DempeyZemkoho2020}. En este contexto, los términos ''líder'' y ''seguidor'' se utilizan para describir los roles en el modelo a optimizar; el líder toma decisiones considerando las posibles reacciones del seguidor, quien a su vez reacciona seleccionando su mejor opción, ver \cite{Sinha2017ARO}.

% Decir que se va ha hablar del enfoque optimista
Dado que en la tesis trataremos sobre problemas binivel de enfoque optimista mostraremos algunos resultados referidos al modelo resultante.


\newpage
% Definición de problema binivel

\textbf{Optimización Binivel Optimista.} Un problema de optimización binivel optimista, se formula como:

\begin{align}
    \min_{x , y} & \quad F(x, y) \notag \\
    \text{s.t.} & \quad g_i(x, y) \leq 0, i=1\ldots q,  \notag \\
    & \quad h_i(x,y) = 0, i=1 \ldots r, \notag\\
    & \quad y \in S(x), \notag\\
    &\intertext{donde $S(x)$ es el conjunto de soluciones óptimas del problema parametrizado por $x$} \tag{\theequation}\\
    \min_{y \in Y(x)} & \quad f(x, y) \notag \\
    \text{s.t.} & \quad v_j(x, y) \leq 0, j=1\ldots s, \notag\\
    & \quad u_j(x,y) = 0, j=1 \ldots t, \notag\\
    %&\text{Definición de un Problema Binivel Optimista} \notag\\
\end{align}
\label{eq:DefBinivelOptimista} 
%\textbf{Donde $M^0(x,y)$ es el conjunto de restricciones comunes para ambos niveles}

\begin{samepage}
%Dimensiones
donde 
% Dimension de x and y
\begin{equation*}
    x \in R^{n},\quad \quad y \in R^{m}
\end{equation*}
\begin{align*}
    %Dimension de F 
& F(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},
%Dimension g_i
& \quad  g_i(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,
%Dimension h_i
& \quad h_i(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,
\\
% Def nivel inferior
%Dimension de f_i
&f(x,y) : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R},
% Dimension de v_j
& \quad v_j(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,
% Dimension u_j
& \quad u_j(x,y)  : \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R} ,
\end{align*} 
\end{samepage}

%\begin{equation*}
%    %Dimension de M_i
%m_i \in M^0(x,y) \| m_i : f \mathbb{R}^{n} \times \mathbb{R}^{m} \to \mathbb{R}
%\end{equation*}

% Esto dejarlo en una sola pagina
%TODO: RESTRICCIONES DEL LIDER Y DEL SEGUIDOR NO IMPLICITA y EXPLICITA
 %TODO: RESTRICCIONES DEL LIDER Y DEL SEGUIDOR NO IMPLICITA y EXPLICITA
\newpage


Esta minimización está sujeta a dos tipos de restricciones: 
%Restricciones explicación old
%las restricciones explícitas para el líder, $x \in X$, donde $X$ es el conjunto de valores factibles para las variables del líder; y las restricciones implícitas impuestas por el seguidor, donde $y$ debe pertenecer al conjunto de soluciones óptimas del problema de optimización del seguidor, $\arg\min\{f(x, y) : y \in Y(x)\}$. En este contexto, $f(x, y)$ es la función objetivo del nivel inferior, y $Y(x)$ representa las restricciones del nivel inferior, las cuales pueden depender de las variables de decisión del líder, $x$.
% Restricciones nuevas
\begin{itemize}
    \item \textbf{Restricciones explícitas:}
    \begin{itemize}
        \item Desigualdades del líder: \( g_i(x,y) \leq 0 \quad \forall i \)
        \item Igualdades del líder: \( h_i(x,y) = 0 \quad \forall i \)
    \end{itemize}
    
    \item \textbf{Restricciones implícitas:}
    \begin{itemize}
        \item Impuestas por el seguidor: \( y \in \arg\min\{f(x, y) : v_j(x,y) \leq 0,\ u_j(x,y) = 0\} \),\\
        donde \( f(x, y) \) es la función objetivo del seguidor
    \end{itemize}
    
	 
	\item También se puede asumir que ambas variables tienen restricciones conjuntas, las restricciones $ g_i(x,y), \quad h_i(x,y), \quad v_j(x,y), \quad u_j(x,y) $ que dependen de las variables $x$ y $y$.
	
	
\end{itemize}
 % Hablar sobre el enfoque optimista
%En el caso del enfoque optimista si para el nivel inferior existen más de un punto que resuelve el problema del nivel inferior y tomará la que más beneficie al nivel superior. 
 % Decir que solo restricciones desigualdad
Por simplicidad solo se consideran restricciones de desigualdad.


%\subsection{Transformación de los problemas de dos niveles}
		
		Los problemas de dos niveles pueden ser reformulados en un problema de un solo nivel al reemplazar el problema del nivel inferior por las condiciones KKT de este en las restricciones del primer nivel. 
		
		%Para el caso de los SLSMG donde se tiene un problema de optimización en el nivel inferior este sustituye por de las condiciones KKT de este, obteniendo un MPEC \autocite{aussel2020}.
        
% Descripción del modelo en KKT
       \begin{table}[H]
        \centering
        \begin{equation}
            \begin{array}{l}
                \underset{\substack{x, y, \lambda_j}}{\min} \quad F(x, y)\\
                s.a \left\{ 
                \begin{array}{l}
                    g_i(x, y) \leq 0, i=1\ldots q,\\
                    \nabla_{y} f(x, y) + \sum_{j=1}^{s} \nabla_{y} v_j(x, y) \lambda_j = 0, \\
                    v_j(x, y) \leq 0, j=1\ldots s,\\
                    v_j(x, y)\lambda_j = 0, j=1\ldots s, \\
                    \lambda_j \geq 0, j=1\ldots s\\
                \end{array}\right.
                \tag{\theequation}
            \end{array}
            \label{eq:KKT_Optimista}
        \end{equation}
        \caption*{MPEC resultante}

    \end{table}
    
% Añadir aclaratoria
Los tres últimos grupos de restricciones expresan que $v$ y $\lambda$ están restringidas en signo y que al menos una es 0. Estas condiciones son conocidas como \textbf{restricciones de complementariedad}. Estos modelos corresponden a la clase de problemas de programación matemática con restricciones de complementariedad (MPEC). A continuación, presentamos los resultados de esta área necesarios para el desarrollo de esta tesis.
%TODO: Como se dijo en la intro existe otra forma, en un problema de programacion matematica  usando funcion del valor extremal sin embargo salvo en casos muy particulares esta no tiene una expresion explicita. La ventaja dsel kkt por mpec es que es una forma explicita, pero se requiere algun tipo de condicion de regularidad del conjunto como LICQ independencia  de v activa, que caso ded no cumpliser poder existir puntos optimos que no lo recoga el kkt. 

\section{Sobre los Programas Matemáticos con Restricciones de Equilibrio (MPEC)}
%Aca va la sección que explica los MPEC
% Que es un MPEC
Un \textbf{Programa Matemático con Restricciones de Equilibrio (MPEC)} es un tipo de programa no lineal que incluye restricciones de equilibrio, específicamente, restricciones de complementariedad.

%Formula MPEC Genérico
\begin{equation}
\begin{aligned}
\min \quad & f(z)  \\
\text{s.t.} \quad & g(z) \leq 0, \quad h(z) = 0 \\
& G(z) \geq 0, \quad H(z) \geq 0, \quad G(z)^T H(z) = 0 \\
&\text{Definición de MPEC} \\
\end{aligned}  
%\tag{\theequation} 
\label{eq:DefMpec}
\end{equation}

%Dimensiones MPEC Genérico
donde $f: \mathbb{R}^n \to \mathbb{R}$, $g: \mathbb{R}^n \to \mathbb{R}^m$, $h: \mathbb{R}^n \to \mathbb{R}^p$, $G: \mathbb{R}^n \to \mathbb{R}^\ell$, y $H: \mathbb{R}^n \to \mathbb{R}^\ell$ son funciones continuamente diferenciables. Debido al término de complementariedad en las restricciones, los programas de este tipo son algunas veces referidos como programas matemáticos

Estas restricciones de complementariedad se expresan como: 

%Ecuación para poner que son las restricciones de complementariedad
\begin{equation}
    G(z) \geq 0, \quad H(z) \geq 0, \quad \text{y} \quad G(z)^T H(z) = 0 \label{eq:RestriccionesComplementariedadAbstracto}
\end{equation}

Los MPEC incluyen restricciones donde el producto de dos funciones (\textit{G} y \textit{H}) debe ser cero, y ambas funciones deben ser no negativas. Esto se conoce como restricción de complementariedad. Debido a las restricciones de complementariedad, los MPEC no cumplen con las condiciones de regularidad estándar, lo que hace que las condiciones de KKT no sean directamente aplicables como condiciones de optimalidad de primer orden. Los MPEC son utilizados para modelar problemas donde existen restricciones de equilibrio, como problemas de ingeniería y economía, ver \cite{Flegel2003AFJ,DempeyZemkoho2020}.


%\subsection{Resultados sobre MPECs}

%Notación de los indices activos del documento
A continuación como en \cite{Flegel2003AFJ}, se introduce las siguientes definiciones.
\begin{definition}[Conjunto de Índices]
Dado un vector factible $z^*$ del MPEC \eqref{eq:DefMpec}, definimos los siguientes \textit{conjuntos de índices}:
\begin{equation}
\begin{aligned}
J_G &:= J_G(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) > 0\} \\
J_{GH}:= J_{GH}:(z^*) := \{i|G_i(z^*) = 0, H_i(z^*) = 0\}  \\
J_H &:= J_H(z^*) := \{i|G_i(z^*) > 0, H_i(z^*) = 0\}  \\
\end{aligned}
\label{eq:ConjuntoDeIndices} 
\end{equation}
\end{definition}

% Definición de TNLP Problema No Lineal Ajustado
Para definir calificaciones de restricción alteradas, introducimos el siguiente problema, dependiente de $z^*$:

\begin{definition}[Programa No Lineal Ajustado (TNLP)]

Un \textit{Programa No Lineal Ajustado $TNLP := TNLP(z^*)$} es:
%TODO: INcomporar indices y rango en que se mueven
\begin{equation}
\begin{aligned} 
\min \quad & f(z) \\
\text{s.t.} \quad & g_{i}(z) \leq 0 \quad h(z) = 0  \\
& G_{\alpha \cup \beta}(z) = 0 \quad G_{\gamma}(z) \geq 0  \\
& H_{\alpha}(z) \geq 0 \quad H_{\gamma \cup \beta}(z) = 0  \\
& \text{Problema No Lineal Ajustado (TNLP)}  
\end{aligned}
\label{eq:ProblemaAbstractoTNLP}
\end{equation}
    
\end{definition}

El TNLP \eqref{eq:ProblemaAbstractoTNLP} puede ahora ser usado para definir variantes MPEC adecuadas de las calificaciones de restricción estándar de independencia lineal, Mangasarian-Fromovitz y Mangasarian-Fromovitz estricta (LICQ, MFCQ, y SMFCQ en su forma abreviada).

\begin{definition}[MPEC-LICQ]
El MPEC \eqref{eq:DefMpec} se dice que satisface la \textit{MPEC-LICQ} (MPEC-MFCQ, MPEC-SMFCQ) en un vector factible $z^*$ si el correspondiente TNLP$(z^*)$ satisface la LICQ (MFCQ, SMFCQ) en ese vector $z^*$.
\end{definition}
    
% Hacer notar que un mínimo de z^* implica la existencia de \lambda^* ....
%En este punto, es importante notar que bajo MPEC-MFCQ, un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec} implica la existencia de un multiplicador de Lagrange $\lambda^*$ tal que $(z^*, \lambda^*)$ satisface las condiciones KKT para el programa \eqref{eq:ProblemaAbstractoTNLP}. Por lo tanto, si asumimos que MPEC-MFCQ se cumple para un mínimo local $z^*$ del MPEC \eqref{eq:DefMpec}, podemos usar cualquier multiplicador de Lagrange $\lambda^*$ (que ahora se sabe que existe) para definir el MPEC-SMFCQ, es decir, tomando $(z^*, \lambda^*)$.

%Definición de los puntos estacionarios del MPEC
% Flegel and Kanzow 2003
En el contexto de los MPEC en \cite{Flegel2003AFJ} se exponen varios tipos de puntos estacionarios que son cruciales para analizar la optimalidad, los cuales son los siguientes:
\begin{definition}[Punto Factible]
    Un \textit{punto factible} $z$ del MPEC se llama débilmente estacionario si existe un multiplicador de Lagrange $\lambda = (\lambda^g, \lambda^h, \lambda^G, \lambda^H)$ tal que se cumplen las siguientes condiciones:
    
%TODO: USar multiplicadores analogos a como esta en el bijnivel de miu lambda beta 
% EN este orde  mui-g, alpha-h beta-G gamma-H
\begin{align}
& \nabla f(z) + \sum_{i=1}^m \lambda_i^g\nabla g_i(z) + \sum_{i=1}^p \lambda_i^h\nabla h_i(z) - \sum_{i=1}^{\ell} [\lambda_i^G\nabla G_i(z) + \lambda_i^H\nabla H_i(z)] = \vec{0} \notag\\
    & \quad \begin{aligned}
        & \lambda_\alpha^G \text{ libre}, \quad \lambda_\beta^G \text{ libre}, \quad \lambda_\gamma^G = 0, \\
        & \lambda_\gamma^H \text{ libre}, \quad \lambda_\beta^H \text{ libre}, \quad \lambda_\alpha^H = 0, \\
        & g(z) \leq 0, \quad \lambda^g \geq 0, \quad (\lambda^g)^T g(z) = 0.
    \end{aligned} \\
& \label{eq:Definicion_punto_debilemente_estacionario} \notag
\end{align}
\end{definition}

% Definición de puntos estacionarios
Este concepto de estacionariedad, sin embargo, es una condición relativamente débil. Existen conceptos más fuertes de estacionariedad que se derivan y estudian en otros lugares. En particular, se tienen las siguientes definiciones:
% un punto factible $z$ con el correspondiente multiplicador de Lagrange $\lambda = (\lambda^g, \lambda^h, \lambda^G, \lambda^H)$ se llama:

\begin{itemize}
% C-estacionario
\item \begin{definition}[Punto C-estacionario]
  El punto $z$ es: \textit{C-estacionario} si, para cada $i \in \beta$, $\lambda_i^G\lambda_i^H \geq 0$ se cumple.
\end{definition}
%M-Estacionario
\item \begin{definition}[Punto M-estacionario]
    El punto $z$ es: \textit{M-estacionario} si, para cada $i \in \beta$, o bien $\lambda_i^G,\lambda_i^H > 0$ $\vee$ $\lambda_i^G \lambda_i^H = 0$.
\end{definition}
%Fuertemente estacionario
\item \begin{definition}[Punto Fuertemente estacionario]
    El punto $z$ es: \textit{fuertemente estacionario} o \textit{estacionario primal-dual} si, para cada $i \in \beta$, $\lambda_i^G, \lambda_i^H \geq 0$.
\end{definition}
% A-estacionario
%\item \begin{definition}[Punto A-estacionario]
%   Sea $z^*$ un punto débilmente estacionario del MPEC \eqref{eq:DefMpec} será \textit{A-estacionario} si existe un multiplicador de Lagrange correspondiente $\lambda^*$ tal que:
%\begin{equation}
%(\lambda_i^G)^* \geq 0 \quad \vee \quad (\lambda_i^H)^* \geq 0 \quad \forall i \in \beta \notag
%\end{equation}
%\end{definition}
\end{itemize}

%TODO:
Estas definiciones son condiciones necesarias de optimalidad bajo ciertas condiciones de regularidad, las m;as fuerte basda en la MPEC-LICQ conlleva al siguiente resultado:
% Teorema que si z^* es min local del MPEC Si se cumple la LICQ entonces existe .....
\begin{theorem} 
Sea $z^* \in \mathbb{R}^n$ un mínimo local del MPEC \eqref{eq:DefMpec}. Si MPEC-LICQ se cumple en $z^*$, entonces existe un único multiplicador de Lagrange $\lambda^*$ tal que $(z^*, \lambda^*)$ es \textit{fuertemente estacionario}.
\end{theorem}

% Modelación en Julia
% Se explica de que va BilevelJump
\section{Modelación en Julia}
% Que es BilevelJump
BilevelJuMP.jl es un paquete de Julia diseñado para modelar y resolver problemas de \textbf{optimización binivel}, también conocidos como problemas de optimización de dos niveles o jerárquica, para más detalles ver \cite{BilevelJump}.
Estos problemas se caracterizan por tener dos niveles de decisión: un nivel superior y un nivel inferior, donde las decisiones del nivel superior influyen en las decisiones del nivel inferior, y viceversa \cite{BilevelJump}.
% Que problemas resuelve
Este paquete permite abordar una amplia variedad de tipos de problemas. En este trabajo usaremos las siguientes bibliotecas:
% Añadir explicación MPEC
\subsection*{JuMP}
% TODO: PONEWr esto  Permite gestionar una variedad de restricciones compatibles con JuMP, tales como restricciones cuadráticas, no lineales y enteras.
%Facilita la transformación de problemas binivel en problemas de programación matemática con restricciones de equilibrio (MPEC) y ofrece métodos para abordar las restricciones de complementariedad que surgen en estos casos.
  %TOD: Poner esto despues de expluicar las reformulaciones
\subsection*{BilevelJuMP}
BilevelJuMP.jl facilita la modelación de problemas que pueden representarse en la sintaxis de JuMP, ver documentación en \cite{JuMPPaper}, incluyendo restricciones lineales y no lineales, variables continuas y enteras, y diferentes tipos de objetivos.
\begin{itemize}
    \item \textbf{Problemas de optimización binivel generales:} BilevelJuMP.jl facilita la modelación de problemas que pueden representarse en la sintaxis de JuMP, ver documentación en \cite{JuMPPaper}, incluyendo restricciones lineales y no lineales, variables continuas y enteras, y diferentes tipos de objetivos.
    
    \item \textbf{Problemas con restricciones de determinados tipos en el nivel superior:} Permite gestionar una variedad de restricciones compatibles con JuMP, tales como restricciones cuadráticas, no lineales y enteras.
    
%TODO: MOdificar esto para decir que hace esto.
    
    
    \item \textbf{Problemas con diferentes tipos de reformulaciones:} Los usuarios pueden experimentar con diversas reformulaciones para las restricciones de complementariedad en los problemas MPEC, incluyendo SOS1, restricciones de indicador, Fortuny-Amat y McCarl (Big-M), entre otros.
    %TODO: POner que es comun a los dos 
    \item \textbf{Problemas que requieren solvers MIP y NLP:} BilevelJuMP.jl puede utilizar tanto solucionadores de \textbf{programación lineal mixta entera (MIP)} como solucionadores de \textbf{programación no lineal (NLP)}, dependiendo de las características del problema y la reformulación elegida.
\end{itemize}

%\subsection{Limitaciones del BilevelJuMP.jl}

A pesar de sus capacidades, BilevelJuMP.jl presenta algunas limitaciones, entre las cuales se encuentran:

\begin{itemize}
    \item Enfrentar dificultades en problemas altamente no lineales o con estructuras de optimización complejas que no se puedan representar adecuadamente en la sintaxis de JuMP.
    \item Existencia de ciertas restricciones que podrían no ser compatibles o que requieren transformaciones adicionales que podrían complicar el modelo.
    \item El problema es de gran escala afectando el rendimiento del solver, el cual puede ser un factor crítico.
    \item La formulación y resolución de problemas muy específicos o especializados podrían no estar completamente optimizadas en el paquete.
\end{itemize}


% Explicación algoritmos 
\section{Métodos de Reformulación para Optimización Binivel}
La optimización binivel presenta desafíos particulares debido a su naturaleza jerárquica y las condiciones de complementariedad resultantes. A continuación, se presentan los principales métodos de reformulación implementados en la literatura, basados en la transformación del MPEC \eqref{eq:KKT_Optimista}.
\subsection{Método Big-M}

El método Big-M (Fortuny-Amat y McCarl)  es una técnica fundamental para reformular problemas de optimización binivel en problemas MPEC. 
Este método aborda específicamente las condiciones de complementariedad que surgen en estas reformulaciones, transformando el problema original en un problema de programación lineal mixta entera (MILP).

La reformulación mediante Big-M introduce un parámetro M suficientemente grande y variables binarias para transformar las condiciones de complementariedad no lineales en restricciones lineales. Para una condición de complementariedad 
$v_j(x,y)\lambda_j = 0$ en \eqref{eq:KKT_Optimista}, el método introduce una variable binaria  $f_j \in \{0,1\}$ y cotas superiores $M_p$, $M_d$ bajo  las siguientes restricciones:

\begin{align}
    v_j(x,y) &\geq -M_p(1 - f_j) \notag \\
    \lambda_j &\leq M_d f_j \\
	%TODO: EN vez sde f_j poner \delta_j
    f_j &\in \{0,1\} \notag
\end{align}

donde $M_p$ y $M_d$ son valores grandes para las variables primales y duales, respectivamente. La efectividad del método depende crucialmente de la selección apropiada de estos valores, que deben ser suficientemente grandes para no excluir la solución óptima, pero no excesivamente grandes para evitar inestabilidades numéricas \cite{BilevelJump}.


\subsection{Método SOS1}

El método de Conjuntos Ordenados Especiales tipo 1 (SOS1) evita el uso de parámetros Big-M mediante restricciones de tipo conjunto. Para cada par complementario $(v_j, \lambda_j)$:

\begin{equation}
%DONDe SOS1 es v_j * \lambda_j 
[v_j(x,y); \lambda_j] \in \text{SOS1} \label{eq:SOS1_reform}
\end{equation}

Esta restricción fuerza que al menos una variable en el par sea cero, preservando la no linealidad original sin necesidad de cotas. Es particularmente eficaz en problemas con estructura cónica \cite{BilevelJump}.


\subsection{Método ProductMode}

El método ProductMode representa un enfoque directo para manejar las condiciones de complementariedad en su forma de producto original. Este método es particularmente útil cuando se trabaja con solucionadores de programación no lineal (NLP), aunque no garantiza la optimalidad global.

La implementación del ProductMode mantiene la restricción de complementariedad en su forma original:

\begin{equation}
    v_j(x,y) \cdot \lambda_j \leq t \label{eq:ProductMode_reg}
\end{equation}

donde $t > 0$ es un parámetro de regularización pequeño. Esta formulación, aunque no satisface las condiciones de calificación de restricciones estándar, es útil para obtener soluciones iniciales y puede ser especialmente efectiva cuando se combina con solucionadores NLP, ver \cite{BilevelJump}.

% TODO: hjacer suempre cierre capitulo, y dicinedo que se dijo y motivar

%\subsection{Comparación de Métodos}
%La Tabla \ref{tab:comparacion_metodos} resume los requisitos y características de cada método:
%
%\begin{table}[H]
%\centering
%\begin{tabular}{l|l|l}
%\textbf{Método} & \textbf{Solver Requerido} & \textbf{Ventajas} \\ \hline
%Big-M & MIP & Estabilidad numérica controlada \\
%SOS1 & MIP con SOS1 & Sin parámetros ad-hoc \\
%ProductMode & NLP & Manejo de no linealidades \\
%\end{tabular}
%\caption{Comparación de métodos de reformulación}
%\label{tab:comparacion_metodos}
%\end{table}
%
%Para casos con restricciones no lineales $v_j(x,y)$, se recomienda combinar ProductMode con técnicas de linealización por tramos \cite[Apéndice B]{BilevelJump}. Todos estos métodos están implementados en BilevelJuMP.jl, permitiendo experimentación con múltiples reformulaciones \cite[Sección 4]{BilevelJump}.
%
%\section{Add}
%\begin{equation}
%    \min_{x,y,\lambda_j,f_j} F(x,y)
%\end{equation}
%
%sujeto a:
%\begin{align}
%    & g_i(x,y) \leq 0, && i = 1,\ldots,q, \\
%    & \nabla_y f(x,y) + \sum_{j=1}^s \nabla_y v_j(x,y) \lambda_j = 0, \\
%    & v_j(x,y) \leq 0, && j = 1,\ldots,s, \\
%    & \lambda_j \geq 0, && j = 1,\ldots,s, \\
%    & v_j(x,y) \geq -M_p \cdot (1-f_j), && \text{(no lineal si } v_j \text{ es no lineal)} \\
%    & \lambda_j \leq M_d \cdot f_j, && j = 1,\ldots,s, \\
%    & f_j \in \{0,1\}, && j = 1,\ldots,s.
%\end{align}